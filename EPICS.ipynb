{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J79NpbXb2Rji",
        "outputId": "b97daa3c-aee2-4d69-fa15-2ced6ade1084"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit opencv-python numpy tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LpljMc2w-hL",
        "outputId": "afe1de4f-d6e3-458a-b51b-3173804add65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.45.1-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.40.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.25.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading streamlit-1.45.1-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.45.1 watchdog-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XgRE7e6dw_PD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic packages\n",
        "!pip install opencv-python\n",
        "!pip install scikit-learn\n",
        "!pip install numpy\n",
        "!pip install matplotlib\n",
        "\n",
        "# Deep learning\n",
        "!pip install tensorflow  # or keras if needed separately\n",
        "\n",
        "# For video reading/writing and support (optional if needed)\n",
        "!pip install imageio\n",
        "!pip install moviepy\n",
        "\n",
        "# tqdm for progress bars\n",
        "!pip install tqdm\n",
        "\n",
        "# If using pandas for data handling\n",
        "!pip install pandas\n",
        "\n",
        "# If you're using any anomaly detection-specific libraries (optional)\n",
        "# !pip install pyod\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gnj6-JZ12VVP",
        "outputId": "54fadcf4-67a8-4918-ad2a-5890c336a223"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.11/dist-packages (2.37.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from imageio) (2.0.2)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio) (11.1.0)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.1.11)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.0.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.37.0)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.6.0)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2025.1.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        },
        "id": "gExYKWAh2B6r",
        "outputId": "842c80dd-8a65-4555-c0e3-7d10f203abed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-04-14 19:42:20.840 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-14 19:42:20.841 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-14 19:42:20.843 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-14 19:42:20.847 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-14 19:42:20.848 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-14 19:42:20.849 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-14 19:42:20.850 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-14 19:42:20.851 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-14 19:42:20.852 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-14 19:42:20.853 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-14 19:42:20.854 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-14 19:42:20.855 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-14 19:42:20.856 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-14 19:42:20.857 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-14 19:42:20.858 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-14 19:42:20.859 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-14 19:42:20.859 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-14 19:42:20.860 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-14 19:42:20.861 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-14 19:42:20.862 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from: crime_predictor_best_generator.h5\n",
            "Error loading model crime_predictor_best_generator.h5: [Errno 2] Unable to synchronously open file (unable to open file: name = 'crime_predictor_best_generator.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nif __name__ == \"__main__\":\\n    # [source: 19] print(\"TensorFlow Version:\", tf.__version__)\\n    # [source: 19] print(\"Num GPUs Available: \", len(tf.config.list_physical_devices(\\'GPU\\')))\\n\\n    # 1. Create list of all video paths and labels\\n    # print(\"--- Gathering Video Files ---\")\\n    # [source: 19] all_video_data = list(video_generator(DATASET_PATH, CRIME_FOLDERS, NORMAL_FOLDER if os.path.exists(os.path.join(DATASET_PATH, NORMAL_FOLDER)) else None))\\n    # if not all_video_data:\\n    #     print(\"Error: No video files found. Check dataset paths and permissions.\") # [cite: 20]\\n    #     exit() # [cite: 20]\\n\\n    # [source: 20] all_video_paths = [item[0] for item in all_video_data]\\n    # [source: 20] all_labels = [item[1] for item in all_video_data]\\n\\n    # print(f\"Found {len(all_video_paths)} total videos.\") # [cite: 20]\\n    # print(f\"Class Distribution: Normal (0): {all_labels.count(0)}, Crime (1): {all_labels.count(1)}\") # [cite: 20]\\n\\n    # Split file paths and labels\\n    # print(\"\\n--- Splitting Data (File Paths) ---\") # [cite: 20]\\n    # try:\\n    #     train_paths, test_paths, train_labels, test_labels = train_test_split(\\n    #         all_video_paths, all_labels,\\n    #         test_size=0.25, random_state=42, stratify=all_labels # [cite: 20]\\n    #     )\\n    #     train_paths, val_paths, train_labels, val_labels = train_test_split(\\n    #         train_paths, train_labels,\\n    #         test_size=0.20, random_state=42, stratify=train_labels # [cite: 21]\\n    #     )\\n    # except ValueError as e: # [cite: 21]\\n    #     print(f\"Error during splitting: {e}\") # [cite: 21]\\n    #     print(\"Check if all classes have enough videos.\") # [cite: 21]\\n    #     exit() # [cite: 21]\\n\\n    # [source: 21] print(f\"Training set size: {len(train_paths)}\")\\n    # print(f\"Validation set size: {len(val_paths)}\") # [cite: 22]\\n    # print(f\"Test set size: {len(test_paths)}\") # [cite: 22]\\n    # del all_video_data, all_video_paths, all_labels # Clear memory [cite: 22]\\n\\n\\n    # 3. Create tf.data Datasets\\n    # print(\"\\n--- Creating Data Generators ---\") # [cite: 22]\\n\\n    # Training Dataset\\n    # [source: 22] train_ds = tf.data.Dataset.from_tensor_slices((train_paths, train_labels))\\n    # train_ds = train_ds.shuffle(len(train_paths)) # Shuffle paths before loading\\n    # Use flat_map to handle videos producing multiple sequences or no sequences\\n    # train_ds = train_ds.flat_map(lambda path, label: tf.data.Dataset.from_tensor_slices(\\n    #     load_and_process_video(path, label, SEQUENCE_LENGTH, IMG_HEIGHT, IMG_WIDTH)) # [cite: 22]\\n    # )\\n    # train_ds = train_ds.batch(BATCH_SIZE) # [cite: 23]\\n    # train_ds = train_ds.prefetch(buffer_size=AUTOTUNE) # Prefetch for performance [cite: 23]\\n\\n    # Validation Dataset\\n    # [source: 23] val_ds = tf.data.Dataset.from_tensor_slices((val_paths, val_labels))\\n    # val_ds = val_ds.flat_map(lambda path, label: tf.data.Dataset.from_tensor_slices(\\n    #     load_and_process_video(path, label, SEQUENCE_LENGTH, IMG_HEIGHT, IMG_WIDTH)) # [cite: 23]\\n    # )\\n    # val_ds = val_ds.batch(BATCH_SIZE)\\n    # val_ds = val_ds.prefetch(buffer_size=AUTOTUNE) # [cite: 24]\\n\\n    # Test Dataset\\n    # [source: 24] test_ds = tf.data.Dataset.from_tensor_slices((test_paths, test_labels))\\n    # test_ds = test_ds.flat_map(lambda path, label: tf.data.Dataset.from_tensor_slices(\\n    #     load_and_process_video(path, label, SEQUENCE_LENGTH, IMG_HEIGHT, IMG_WIDTH)) # [cite: 24]\\n    # )\\n    # test_ds = test_ds.batch(BATCH_SIZE)\\n    # test_ds = test_ds.prefetch(buffer_size=AUTOTUNE) # [cite: 24]\\n\\n\\n    # 4. Build Model\\n    # print(\"\\n--- Building Model ---\") # [cite: 24]\\n    # Assuming you want to build/train here too, otherwise load pre-trained\\n    # model = build_model(SEQUENCE_LENGTH, IMG_HEIGHT, IMG_WIDTH,\\n    #                       LSTM_UNITS, DENSE_UNITS, DROPOUT_RATE,\\n    #                       NUM_CLASSES, LEARNING_RATE) # [cite: 25, 28]\\n\\n    # 5. Train Model using the datasets\\n    # print(\"\\n--- Starting Training ---\") # [cite: 25]\\n    # checkpoint_path = \"crime_predictor_best_generator.keras\" # New checkpoint name [cite: 25, 28]\\n    # model_checkpoint = ModelCheckpoint(filepath=checkpoint_path,\\n    #                                    save_best_only=True, # [cite: 26, 29]\\n    #                                    monitor=\\'val_accuracy\\', # [cite: 26, 29]\\n    #                                    mode=\\'max\\', # [cite: 27, 30]\\n    #                                    verbose=1) # [cite: 27]\\n    # early_stopping = EarlyStopping(monitor=\\'val_loss\\', # [cite: 27, 30]\\n    #                                patience=10, # [cite: 27, 30]\\n    #                                mode=\\'min\\', # [cite: 28, 31]\\n    #                                restore_best_weights=True, # [cite: 28, 31]\\n    #                                verbose=1) # [cite: 29, 32]\\n\\n    # history = model.fit(\\n    #     train_ds,\\n    #     epochs=EPOCHS,\\n    #     validation_data=val_ds,\\n    #     callbacks=[model_checkpoint, early_stopping],\\n    #     verbose=1 # [cite: 29]\\n    # ) # [cite: 30, 32]\\n\\n    # print(\"\\n--- Training Complete ---\") # [cite: 30]\\n    # try:\\n    #      pass # plot_training_history(history) # [cite: 18, 30, 32] # Implement or remove plotting\\n    # except Exception as plot_err:\\n    #     print(f\"Could not plot training history: {plot_err}\") # [cite: 30]\\n\\n\\n    # 6. Evaluate Model\\n    # print(\"\\n--- Evaluating on Test Set using Generator ---\") # [cite: 30]\\n    # print(f\"Loading best model from: {checkpoint_path}\") # [cite: 30]\\n    # try:\\n    #     best_model = keras.models.load_model(checkpoint_path) # [cite: 31, 33]\\n    #     # Evaluate using the test dataset generator\\n    #     loss, accuracy, precision, recall = best_model.evaluate(test_ds, verbose=1) # [cite: 31, 33]\\n    #     print(f\"Test Loss: {loss:.4f}\") # [cite: 31]\\n    #     print(f\"Test Accuracy: {accuracy:.4f}\") # [cite: 31]\\n    #     print(f\"Test Precision: {precision:.4f}\") # [cite: 31]\\n    #     print(f\"Test Recall: {recall:.4f}\") # [cite: 31, 34]\\n\\n    #     # Detailed ClasFsification Report\\n    #     print(\"\\nGenerating Classification Report (may take time)...\") # [cite: 32]\\n    #     y_true = []\\n    #     y_pred_prob = []\\n    #     for batch_x, batch_y in test_ds: # [cite: 32]\\n    #          y_true.extend(batch_y.numpy()) # [cite: 32]\\n    #          batch_pred = best_model.predict(batch_x, verbose=0) # [cite: 32]\\n    #          y_pred_prob.extend(batch_pred.flatten()) # [cite: 32]\\n\\n    #     y_pred = (np.array(y_pred_prob) > 0.5).astype(int) # [cite: 33]\\n    #     y_true = np.array(y_true) # [cite: 33]\\n\\n    #     print(\"\\nClassification Report:\") # [cite: 33]\\n    #     print(classification_report(y_true, y_pred, target_names=[\\'Normal (0)\\', \\'Crime (1)\\'])) # [cite: 33, 34]\\n\\n    #     print(\"\\nConfusion Matrix:\") # [cite: 33]\\n    #     print(confusion_matrix(y_true, y_pred)) # [cite: 33, 34]\\n\\n    # except Exception as e: # [cite: 33]\\n    #     print(f\"Error during evaluation with best model: {e}\") # [cite: 33, 35]\\n    #     # Optionally, try evaluating with the model state at the end of training\\n    #     # print(\"Evaluating with model state at end of training...\") # [cite: 34]\\n    #     # loss, accuracy, precision, recall = model.evaluate(test_ds, verbose=1) # [cite: 34, 36]\\n    #     # print(f\"Test Loss (End of Training): {loss:.4f}\") # [cite: 34]\\n    #     # print(f\"Test Accuracy (End of Training): {accuracy:.4f}\") # [cite: 34]\\n    #     # print(f\"Test Precision (End of Training): {precision:.4f}\") # [cite: 34]\\n    #     # print(f\"Test Recall (End of Training): {recall:.4f}\") # [cite: 34]\\n\\n    # 7. Example Prediction (This logic is now integrated into the Streamlit part)\\n    # print(\"\\n--- Example Prediction ---\") # [cite: 34]\\n    # test_video_path = \"/content/drive/MyDrive/RoadAccidents105_x264.mp4\" # Keep your test path [cite: 37]\\n    # if os.path.exists(test_video_path): # [cite: 37]\\n    #     test_sequences_np = load_single_video_for_prediction(test_video_path, SEQUENCE_LENGTH, IMG_HEIGHT, IMG_WIDTH) # [cite: 34, 37]\\n    #     if test_sequences_np is not None and len(test_sequences_np) > 0: # [cite: 37, 38]\\n    #         print(f\"Predicting on video: {test_video_path} ({len(test_sequences_np)} sequences)\") # [cite: 38]\\n    #         # Use the loaded best_model (ensure it\\'s loaded if running this block)\\n    #         # best_model = load_keras_model() # Or however you load it here\\n    #         # predictions = best_model.predict(test_sequences_np) # [cite: 37, 38]\\n    #         # avg_prediction = np.mean(predictions) # [cite: 38]\\n    #         # final_label = \"Crime\" if avg_prediction > 0.5 else \"Normal\" # [cite: 38]\\n    #         # print(f\"Average Predicted Probability: {avg_prediction:.4f}\") # [cite: 39]\\n    #         # print(f\"Final Prediction for the video: {final_label}\") # [cite: 38, 39]\\n    #     else:\\n    #         print(f\"Could not extract valid sequences from {test_video_path}\") # [cite: 39]\\n    # else:\\n    #     print(f\"Test video not found: {test_video_path}\") # [cite: 39]\\n\\n    # print(\"\\n--- Script Finished ---\") # [cite: 39]\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# [source: 1] import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras.layers import (Input, Dense, LSTM, TimeDistributed,\n",
        "                                     Flatten, Dropout, GlobalAveragePooling1D) # Keep necessary layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D  # Import this layer\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "# [source: 2] import matplotlib.pyplot as plt # Removed for Streamlit, unless needed for other plots\n",
        "import time\n",
        "import glob\n",
        "import itertools # Needed for generator chaining\n",
        "import tempfile # Needed for Streamlit file handling\n",
        "import streamlit as st # Import Streamlit\n",
        "\n",
        "# --- Configuration (Keep as before, adjust paths/parameters if needed) ---\n",
        "# [source: 2] DATASET_PATH = '/content/drive/MyDrive/Training'\n",
        "# [source: 2] NORMAL_FOLDER = 'Training-Normal-Videos-Part-1'  # ADJUST THIS\n",
        "# [source: 2] CRIME_FOLDERS = [\"Abuse\", \"Assault\", \"Explosion\", \"Fighting\", \"RoadAccidents\", \"Robbery\", \"Shooting\"] # ADJUST THIS\n",
        "\n",
        "IMG_HEIGHT = 128 # [cite: 2]\n",
        "IMG_WIDTH = 128 # [cite: 2]\n",
        "SEQUENCE_LENGTH = 20 # [cite: 2]\n",
        "# [source: 3] NUM_CLASSES = 1 # Binary classification\n",
        "PRETRAINED_MODEL = MobileNetV2 # [cite: 3]\n",
        "FEATURE_EXTRACTOR_LAYER = 'out_relu' # [cite: 3]\n",
        "LSTM_UNITS = 64 # [cite: 3]\n",
        "DENSE_UNITS = 32 # [cite: 3]\n",
        "DROPOUT_RATE = 0.4 # [cite: 3]\n",
        "# [source: 3] BATCH_SIZE = 8\n",
        "# [source: 3] EPOCHS = 2\n",
        "# [source: 3] LEARNING_RATE = 0.0005\n",
        "# [source: 3] AUTOTUNE = tf.data.AUTOTUNE # For tf.data pipeline\n",
        "\n",
        "# --- Helper Functions (Keep as they are) ---\n",
        "\n",
        "# 1. Generator to yield video paths and labels (Used for training, not Streamlit app)\n",
        "def video_generator(dataset_path, crime_folders, normal_folder=None):\n",
        "# [source: 4]     \"\"\"Yields (video_path, label) tuples.\"\"\"\n",
        "    # Crime videos (Label = 1)\n",
        "    for crime_type in crime_folders:\n",
        "        folder_path = os.path.join(dataset_path, crime_type)\n",
        "        if os.path.isdir(folder_path):\n",
        "            video_paths = glob.glob(os.path.join(folder_path, '*.mp4')) + \\\n",
        "                          glob.glob(os.path.join(folder_path, '*.avi')) # [cite: 4]\n",
        "            for video_path in video_paths:\n",
        "                yield video_path, 1\n",
        "\n",
        "    # Normal videos (Label = 0), only if normal_folder is provided\n",
        "    if normal_folder:\n",
        "        normal_folder_path = os.path.join(dataset_path, normal_folder)\n",
        "        if os.path.isdir(normal_folder_path): # [cite: 5]\n",
        "            video_paths = glob.glob(os.path.join(normal_folder_path, '*.mp4')) + \\\n",
        "                          glob.glob(os.path.join(normal_folder_path, '*.avi')) # [cite: 5]\n",
        "            for video_path in video_paths:\n",
        "                yield video_path, 0\n",
        "# [source: 6]         else:\n",
        "            print(f\"Warning: Normal folder not found: {normal_folder_path}\") # [cite: 6]\n",
        "\n",
        "# 2. Function to load and process frames for tf.data (Used for training, not Streamlit app)\n",
        "@tf.function # Decorator for potential graph mode optimization\n",
        "def load_and_process_video(video_path, label, sequence_length, img_height, img_width):\n",
        "# [source: 6]     \"\"\"Loads frames from a single video path using tf.py_function.\"\"\"\n",
        "    def _load_frames(path):\n",
        "        path = path.numpy().decode('utf-8') # Decode tensor string\n",
        "        sequences = []\n",
        "        cap = cv2.VideoCapture(path)\n",
        "        if not cap.isOpened(): # [cite: 3, 6]\n",
        "# [source: 7]             print(f\"Error: Could not open video {path}\") # [cite: 4, 7]\n",
        "            # Return an empty array with the correct shape structure if error\n",
        "            # Shape: (num_sequences, sequence_length, height, width, channels)\n",
        "            return np.zeros((0, sequence_length, img_height, img_width, 3), dtype=np.float32) # [cite: 7]\n",
        "\n",
        "        frames = []\n",
        "        try:\n",
        "            while True: # [cite: 8]\n",
        "                ret, frame = cap.read() # [cite: 8]\n",
        "                if not ret:\n",
        "                    break\n",
        "                resized_frame = cv2.resize(frame, (img_width, img_height)) # [cite: 5, 8]\n",
        "                normalized_frame = resized_frame / 255.0 # [cite: 5, 9]\n",
        "                frames.append(normalized_frame) # [cite: 9]\n",
        "\n",
        "                if len(frames) == sequence_length:\n",
        "                    sequences.append(np.array(frames)) # [cite: 5, 9]\n",
        "                    frames = frames[sequence_length // 2:] # Overlap [cite: 6, 9]\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing video {path_str}: {e}\")\n",
        "            # Return empty list to indicate failure inside py_function\n",
        "            return np.array([], dtype=np.float32).reshape(0, sequence_length, img_height, img_width, 3) # Reshape\n",
        "        finally:\n",
        "            if cap is not None: # Check if cap was successfully opened\n",
        "                cap.release()\n",
        "\n",
        "        if not sequences:\n",
        "             # Handle videos shorter than sequence length or empty videos\n",
        "             # Return empty list to indicate no sequences\n",
        "             return np.array([], dtype=np.float32).reshape(0, sequence_length, img_height, img_width, 3) # Reshape\n",
        "\n",
        "        return np.array(sequences, dtype=np.float32) # Return the valid sequences\n",
        "    # Use tf.py_function to wrap the Python code\n",
        "    sequences = tf.py_function(\n",
        "        _load_frames,\n",
        "        [video_path],\n",
        "        tf.float32 # Output type [cite: 11]\n",
        "    )\n",
        "\n",
        "    # Set shape information which is lost by py_function\n",
        "# [source: 12]     # Shape: (num_sequences, sequence_length, height, width, channels)\n",
        "    sequences.set_shape([None, sequence_length, img_height, img_width, 3]) # [cite: 12]\n",
        "\n",
        "    # Repeat the label for each sequence extracted from the video\n",
        "    num_sequences = tf.shape(sequences)[0]\n",
        "    repeated_labels = tf.repeat(label, num_sequences) # [cite: 12]\n",
        "\n",
        "    return sequences, repeated_labels\n",
        "\n",
        "# --- Build Model (Keep the build_model function as it is, needed for loading) ---\n",
        "def build_model(sequence_length, img_height, img_width, lstm_units, dense_units, dropout_rate,\n",
        "                num_classes, learning_rate): # Add learning_rate back if needed for compilation during loading\n",
        "# [source: 13]     \"\"\"Builds the CNN + LSTM model.\"\"\"\n",
        "    input_shape = (sequence_length, img_height, img_width, 3)\n",
        "    video_input = Input(shape=input_shape, name='video_input') # [cite: 13]\n",
        "\n",
        "    # Load pre-trained CNN (without top classification layer)\n",
        "    base_model = PRETRAINED_MODEL(\n",
        "        include_top=False,\n",
        "        weights='imagenet',\n",
        "        input_shape=(img_height, img_width, 3) # [cite: 13]\n",
        "    )\n",
        "    base_model.trainable = False\n",
        "\n",
        "    # --- Feature Extraction ---\n",
        "# [source: 14]     # Create a model that outputs the features from the chosen layer\n",
        "    intermediate_model = Model(inputs=base_model.input,\n",
        "                               outputs=base_model.get_layer(FEATURE_EXTRACTOR_LAYER).output,\n",
        "                               # Use the corrected layer name\n",
        "                               name=\"intermediate_feature_extractor\") # [cite: 15]\n",
        "\n",
        "    # Wrap the intermediate model AND a pooling layer with TimeDistributed\n",
        "    # This applies the feature extractor and pooling to each frame (time step)\n",
        "    time_distributed_features = TimeDistributed(\n",
        "        keras.Sequential([  # Add a Sequential wrapper\n",
        "            intermediate_model, # [cite: 15]\n",
        "            GlobalAveragePooling2D()  # Add pooling here to flatten spatial dimensions # [cite: 15]\n",
        "        ]),\n",
        "        name='time_distributed_features' # [cite: 16]\n",
        "    )(video_input) # [cite: 16]\n",
        "\n",
        "    # --- Temporal Learning (LSTM) ---\n",
        "    # Output of TimeDistributed(GlobalAveragePooling2D) should be (batch, seq_len, features)\n",
        "    # which is suitable for LSTM\n",
        "    lstm_out = LSTM(lstm_units, return_sequences=False, name='lstm_layer')(time_distributed_features) # [cite: 16]\n",
        "    lstm_out = Dropout(dropout_rate)(lstm_out)\n",
        "\n",
        "    # --- Classification Head ---\n",
        "    x = Dense(dense_units, activation='relu', name='dense_1')(lstm_out)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "# [source: 17]     output = Dense(num_classes, activation='sigmoid', name='output_layer')(x) # num_classes should be 1 for binary\n",
        "\n",
        "    # --- Compile Model ---\n",
        "    model = Model(inputs=video_input, outputs=output, name='CrimePredictor') # [cite: 17]\n",
        "    # Optimizer is needed for loading, but learning rate might not be critical if just predicting\n",
        "    optimizer = Adam(learning_rate=learning_rate if learning_rate else 0.001) # Provide a default if needed\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='binary_crossentropy', # [cite: 17]\n",
        "                  metrics=['accuracy',\n",
        "                           tf.keras.metrics.Precision(name='precision'), # [cite: 18]\n",
        "                           tf.keras.metrics.Recall(name='recall')]) # [cite: 18]\n",
        "\n",
        "    # print(\"Model Built Successfully:\") # Comment out for Streamlit app\n",
        "    # model.summary(expand_nested=True) # Comment out for Streamlit app\n",
        "    return model\n",
        "\n",
        "\n",
        "# --- Function to load the trained Keras model ---\n",
        "@st.cache_resource\n",
        "def load_keras_model(model_path=\"crime_predictor_best_generator.h5\"): # Default path\n",
        "    print(f\"Loading model from: {model_path}\")\n",
        "    try:\n",
        "        model = keras.models.load_model(model_path) # This line fails\n",
        "        print(\"Model loaded successfully.\")\n",
        "        return model\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error loading model: {e}\") # You are seeing this error\n",
        "        print(f\"Error loading model {model_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# How it's called in the Streamlit section\n",
        "model = load_keras_model() # Uses the default path\n",
        "\n",
        "# --- Function to process a single video file for prediction (Keep as is) ---\n",
        "def load_single_video_for_prediction(video_path, sequence_length, img_height, img_width):\n",
        "    \"\"\"Loads frames from a single video path for prediction.\"\"\"\n",
        "    # This is similar to the _load_frames in load_and_process_video\n",
        "    # but returns directly, not wrapped in tf.py_function\n",
        "# [source: 35]     sequences = []\n",
        "    cap = cv2.VideoCapture(video_path) # [cite: 35]\n",
        "    if not cap.isOpened(): return [] # [cite: 35]\n",
        "    frames = []\n",
        "    try:\n",
        "        while True:\n",
        "            ret, frame = cap.read() # [cite: 35]\n",
        "            if not ret: break\n",
        "            resized_frame = cv2.resize(frame, (img_width, img_height)) # [cite: 36]\n",
        "            normalized_frame = resized_frame / 255.0 # [cite: 36]\n",
        "            frames.append(normalized_frame) # [cite: 36]\n",
        "            if len(frames) == sequence_length:\n",
        "                sequences.append(np.array(frames)) # [cite: 36]\n",
        "# [source: 37]                 frames = frames[sequence_length // 2:] # Overlap [cite: 9, 37]\n",
        "    finally:\n",
        "        cap.release() # [cite: 10, 37]\n",
        "    return np.array(sequences, dtype=np.float32) if sequences else None # [cite: 11, 37]\n",
        "\n",
        "\n",
        "# --- Streamlit App ---\n",
        "st.title(\"Crime Detection from Video Footage\")\n",
        "st.write(\"Upload a video file to predict if it contains crime-related activity.\")\n",
        "\n",
        "# Load the trained model\n",
        "# Make sure 'crime_predictor_best_generator.keras' is accessible [cite: 25]\n",
        "model = load_keras_model()\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Choose a video...\", type=[\"mp4\", \"avi\"])\n",
        "\n",
        "if uploaded_file is not None and model is not None:\n",
        "    # Display the video\n",
        "    st.video(uploaded_file)\n",
        "\n",
        "    if st.button('Predict Activity'):\n",
        "        with st.spinner('Processing video and making prediction...'):\n",
        "            # Save temporary file to pass its path\n",
        "            with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmpfile:\n",
        "                tmpfile.write(uploaded_file.getvalue())\n",
        "                temp_video_path = tmpfile.name\n",
        "\n",
        "            # Process the video\n",
        "            sequences_np = load_single_video_for_prediction(\n",
        "                temp_video_path, SEQUENCE_LENGTH, IMG_HEIGHT, IMG_WIDTH\n",
        "            )\n",
        "\n",
        "            if sequences_np is not None and len(sequences_np) > 0: # [cite: 37, 38]\n",
        "                # Make prediction\n",
        "                predictions = model.predict(sequences_np) # [cite: 37, 38]\n",
        "                avg_prediction = np.mean(predictions) # [cite: 38]\n",
        "                final_label = \"Crime\" if avg_prediction > 0.5 else \"Normal\" # [cite: 38]\n",
        "\n",
        "                # Display result\n",
        "                st.write(f\"Average Predicted Probability: {avg_prediction:.4f}\") # [cite: 39]\n",
        "                if final_label == \"Crime\":\n",
        "                    st.error(f\"Prediction: {final_label}\") # [cite: 38, 39]\n",
        "                else:\n",
        "                    st.success(f\"Prediction: {final_label}\") # [cite: 38, 39]\n",
        "            else:\n",
        "                st.warning(f\"Could not extract valid sequences from the uploaded video.\") # [cite: 39]\n",
        "\n",
        "            # Clean up temporary file\n",
        "            os.remove(temp_video_path)\n",
        "elif model is None:\n",
        "    st.error(\"Model could not be loaded. Please ensure the model file is available.\")\n",
        "\n",
        "# --- Original Main Execution Block (Commented out for Streamlit App) ---\n",
        "# This part contains the training and evaluation logic from your original script.\n",
        "# Keep it commented out or remove it if this script is *only* for the Streamlit app.\n",
        "\"\"\"\n",
        "if __name__ == \"__main__\":\n",
        "    # [source: 19] print(\"TensorFlow Version:\", tf.__version__)\n",
        "    # [source: 19] print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "\n",
        "    # 1. Create list of all video paths and labels\n",
        "    # print(\"--- Gathering Video Files ---\")\n",
        "    # [source: 19] all_video_data = list(video_generator(DATASET_PATH, CRIME_FOLDERS, NORMAL_FOLDER if os.path.exists(os.path.join(DATASET_PATH, NORMAL_FOLDER)) else None))\n",
        "    # if not all_video_data:\n",
        "    #     print(\"Error: No video files found. Check dataset paths and permissions.\") # [cite: 20]\n",
        "    #     exit() # [cite: 20]\n",
        "\n",
        "    # [source: 20] all_video_paths = [item[0] for item in all_video_data]\n",
        "    # [source: 20] all_labels = [item[1] for item in all_video_data]\n",
        "\n",
        "    # print(f\"Found {len(all_video_paths)} total videos.\") # [cite: 20]\n",
        "    # print(f\"Class Distribution: Normal (0): {all_labels.count(0)}, Crime (1): {all_labels.count(1)}\") # [cite: 20]\n",
        "\n",
        "    # Split file paths and labels\n",
        "    # print(\"\\n--- Splitting Data (File Paths) ---\") # [cite: 20]\n",
        "    # try:\n",
        "    #     train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
        "    #         all_video_paths, all_labels,\n",
        "    #         test_size=0.25, random_state=42, stratify=all_labels # [cite: 20]\n",
        "    #     )\n",
        "    #     train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
        "    #         train_paths, train_labels,\n",
        "    #         test_size=0.20, random_state=42, stratify=train_labels # [cite: 21]\n",
        "    #     )\n",
        "    # except ValueError as e: # [cite: 21]\n",
        "    #     print(f\"Error during splitting: {e}\") # [cite: 21]\n",
        "    #     print(\"Check if all classes have enough videos.\") # [cite: 21]\n",
        "    #     exit() # [cite: 21]\n",
        "\n",
        "    # [source: 21] print(f\"Training set size: {len(train_paths)}\")\n",
        "    # print(f\"Validation set size: {len(val_paths)}\") # [cite: 22]\n",
        "    # print(f\"Test set size: {len(test_paths)}\") # [cite: 22]\n",
        "    # del all_video_data, all_video_paths, all_labels # Clear memory [cite: 22]\n",
        "\n",
        "\n",
        "    # 3. Create tf.data Datasets\n",
        "    # print(\"\\n--- Creating Data Generators ---\") # [cite: 22]\n",
        "\n",
        "    # Training Dataset\n",
        "    # [source: 22] train_ds = tf.data.Dataset.from_tensor_slices((train_paths, train_labels))\n",
        "    # train_ds = train_ds.shuffle(len(train_paths)) # Shuffle paths before loading\n",
        "    # Use flat_map to handle videos producing multiple sequences or no sequences\n",
        "    # train_ds = train_ds.flat_map(lambda path, label: tf.data.Dataset.from_tensor_slices(\n",
        "    #     load_and_process_video(path, label, SEQUENCE_LENGTH, IMG_HEIGHT, IMG_WIDTH)) # [cite: 22]\n",
        "    # )\n",
        "    # train_ds = train_ds.batch(BATCH_SIZE) # [cite: 23]\n",
        "    # train_ds = train_ds.prefetch(buffer_size=AUTOTUNE) # Prefetch for performance [cite: 23]\n",
        "\n",
        "    # Validation Dataset\n",
        "    # [source: 23] val_ds = tf.data.Dataset.from_tensor_slices((val_paths, val_labels))\n",
        "    # val_ds = val_ds.flat_map(lambda path, label: tf.data.Dataset.from_tensor_slices(\n",
        "    #     load_and_process_video(path, label, SEQUENCE_LENGTH, IMG_HEIGHT, IMG_WIDTH)) # [cite: 23]\n",
        "    # )\n",
        "    # val_ds = val_ds.batch(BATCH_SIZE)\n",
        "    # val_ds = val_ds.prefetch(buffer_size=AUTOTUNE) # [cite: 24]\n",
        "\n",
        "    # Test Dataset\n",
        "    # [source: 24] test_ds = tf.data.Dataset.from_tensor_slices((test_paths, test_labels))\n",
        "    # test_ds = test_ds.flat_map(lambda path, label: tf.data.Dataset.from_tensor_slices(\n",
        "    #     load_and_process_video(path, label, SEQUENCE_LENGTH, IMG_HEIGHT, IMG_WIDTH)) # [cite: 24]\n",
        "    # )\n",
        "    # test_ds = test_ds.batch(BATCH_SIZE)\n",
        "    # test_ds = test_ds.prefetch(buffer_size=AUTOTUNE) # [cite: 24]\n",
        "\n",
        "\n",
        "    # 4. Build Model\n",
        "    # print(\"\\n--- Building Model ---\") # [cite: 24]\n",
        "    # Assuming you want to build/train here too, otherwise load pre-trained\n",
        "    # model = build_model(SEQUENCE_LENGTH, IMG_HEIGHT, IMG_WIDTH,\n",
        "    #                       LSTM_UNITS, DENSE_UNITS, DROPOUT_RATE,\n",
        "    #                       NUM_CLASSES, LEARNING_RATE) # [cite: 25, 28]\n",
        "\n",
        "    # 5. Train Model using the datasets\n",
        "    # print(\"\\n--- Starting Training ---\") # [cite: 25]\n",
        "    # checkpoint_path = \"crime_predictor_best_generator.keras\" # New checkpoint name [cite: 25, 28]\n",
        "    # model_checkpoint = ModelCheckpoint(filepath=checkpoint_path,\n",
        "    #                                    save_best_only=True, # [cite: 26, 29]\n",
        "    #                                    monitor='val_accuracy', # [cite: 26, 29]\n",
        "    #                                    mode='max', # [cite: 27, 30]\n",
        "    #                                    verbose=1) # [cite: 27]\n",
        "    # early_stopping = EarlyStopping(monitor='val_loss', # [cite: 27, 30]\n",
        "    #                                patience=10, # [cite: 27, 30]\n",
        "    #                                mode='min', # [cite: 28, 31]\n",
        "    #                                restore_best_weights=True, # [cite: 28, 31]\n",
        "    #                                verbose=1) # [cite: 29, 32]\n",
        "\n",
        "    # history = model.fit(\n",
        "    #     train_ds,\n",
        "    #     epochs=EPOCHS,\n",
        "    #     validation_data=val_ds,\n",
        "    #     callbacks=[model_checkpoint, early_stopping],\n",
        "    #     verbose=1 # [cite: 29]\n",
        "    # ) # [cite: 30, 32]\n",
        "\n",
        "    # print(\"\\n--- Training Complete ---\") # [cite: 30]\n",
        "    # try:\n",
        "    #      pass # plot_training_history(history) # [cite: 18, 30, 32] # Implement or remove plotting\n",
        "    # except Exception as plot_err:\n",
        "    #     print(f\"Could not plot training history: {plot_err}\") # [cite: 30]\n",
        "\n",
        "\n",
        "    # 6. Evaluate Model\n",
        "    # print(\"\\n--- Evaluating on Test Set using Generator ---\") # [cite: 30]\n",
        "    # print(f\"Loading best model from: {checkpoint_path}\") # [cite: 30]\n",
        "    # try:\n",
        "    #     best_model = keras.models.load_model(checkpoint_path) # [cite: 31, 33]\n",
        "    #     # Evaluate using the test dataset generator\n",
        "    #     loss, accuracy, precision, recall = best_model.evaluate(test_ds, verbose=1) # [cite: 31, 33]\n",
        "    #     print(f\"Test Loss: {loss:.4f}\") # [cite: 31]\n",
        "    #     print(f\"Test Accuracy: {accuracy:.4f}\") # [cite: 31]\n",
        "    #     print(f\"Test Precision: {precision:.4f}\") # [cite: 31]\n",
        "    #     print(f\"Test Recall: {recall:.4f}\") # [cite: 31, 34]\n",
        "\n",
        "    #     # Detailed ClasFsification Report\n",
        "    #     print(\"\\nGenerating Classification Report (may take time)...\") # [cite: 32]\n",
        "    #     y_true = []\n",
        "    #     y_pred_prob = []\n",
        "    #     for batch_x, batch_y in test_ds: # [cite: 32]\n",
        "    #          y_true.extend(batch_y.numpy()) # [cite: 32]\n",
        "    #          batch_pred = best_model.predict(batch_x, verbose=0) # [cite: 32]\n",
        "    #          y_pred_prob.extend(batch_pred.flatten()) # [cite: 32]\n",
        "\n",
        "    #     y_pred = (np.array(y_pred_prob) > 0.5).astype(int) # [cite: 33]\n",
        "    #     y_true = np.array(y_true) # [cite: 33]\n",
        "\n",
        "    #     print(\"\\nClassification Report:\") # [cite: 33]\n",
        "    #     print(classification_report(y_true, y_pred, target_names=['Normal (0)', 'Crime (1)'])) # [cite: 33, 34]\n",
        "\n",
        "    #     print(\"\\nConfusion Matrix:\") # [cite: 33]\n",
        "    #     print(confusion_matrix(y_true, y_pred)) # [cite: 33, 34]\n",
        "\n",
        "    # except Exception as e: # [cite: 33]\n",
        "    #     print(f\"Error during evaluation with best model: {e}\") # [cite: 33, 35]\n",
        "    #     # Optionally, try evaluating with the model state at the end of training\n",
        "    #     # print(\"Evaluating with model state at end of training...\") # [cite: 34]\n",
        "    #     # loss, accuracy, precision, recall = model.evaluate(test_ds, verbose=1) # [cite: 34, 36]\n",
        "    #     # print(f\"Test Loss (End of Training): {loss:.4f}\") # [cite: 34]\n",
        "    #     # print(f\"Test Accuracy (End of Training): {accuracy:.4f}\") # [cite: 34]\n",
        "    #     # print(f\"Test Precision (End of Training): {precision:.4f}\") # [cite: 34]\n",
        "    #     # print(f\"Test Recall (End of Training): {recall:.4f}\") # [cite: 34]\n",
        "\n",
        "    # 7. Example Prediction (This logic is now integrated into the Streamlit part)\n",
        "    # print(\"\\n--- Example Prediction ---\") # [cite: 34]\n",
        "    # test_video_path = \"/content/drive/MyDrive/RoadAccidents105_x264.mp4\" # Keep your test path [cite: 37]\n",
        "    # if os.path.exists(test_video_path): # [cite: 37]\n",
        "    #     test_sequences_np = load_single_video_for_prediction(test_video_path, SEQUENCE_LENGTH, IMG_HEIGHT, IMG_WIDTH) # [cite: 34, 37]\n",
        "    #     if test_sequences_np is not None and len(test_sequences_np) > 0: # [cite: 37, 38]\n",
        "    #         print(f\"Predicting on video: {test_video_path} ({len(test_sequences_np)} sequences)\") # [cite: 38]\n",
        "    #         # Use the loaded best_model (ensure it's loaded if running this block)\n",
        "    #         # best_model = load_keras_model() # Or however you load it here\n",
        "    #         # predictions = best_model.predict(test_sequences_np) # [cite: 37, 38]\n",
        "    #         # avg_prediction = np.mean(predictions) # [cite: 38]\n",
        "    #         # final_label = \"Crime\" if avg_prediction > 0.5 else \"Normal\" # [cite: 38]\n",
        "    #         # print(f\"Average Predicted Probability: {avg_prediction:.4f}\") # [cite: 39]\n",
        "    #         # print(f\"Final Prediction for the video: {final_label}\") # [cite: 38, 39]\n",
        "    #     else:\n",
        "    #         print(f\"Could not extract valid sequences from {test_video_path}\") # [cite: 39]\n",
        "    # else:\n",
        "    #     print(f\"Test video not found: {test_video_path}\") # [cite: 39]\n",
        "\n",
        "    # print(\"\\n--- Script Finished ---\") # [cite: 39]\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run /usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjxxLSrRztHH",
        "outputId": "d2ea9324-c5ce-4610-e198-d6449a636f92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: streamlit: command not found\n"
          ]
        }
      ]
    }
  ]
}